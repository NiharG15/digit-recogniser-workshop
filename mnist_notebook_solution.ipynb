{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recogniser using Convolutional Neural Network\n",
    "\n",
    "\n",
    "In this workshop we are going a develop and train a deep neural network called convolutional neural network to recognise handwritten digits. We'll be using the MNIST (\"Modified National Institute of Standards and Technology\") dataset, also considered as the \"Hello World\" dataset in computer vision/deep learning. It contains a large set of human handwritten and annotated digit images.\n",
    "\n",
    "By the end of the tutorial you will have learnt how convolutional neural networks work, how to deploy pre-trained model, how to visualise the results. We'll build this neural net using tensorflow and deploy the pretrained model as rest api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Verify TensorFlow is Installed\n",
    "\n",
    "We'll start of by first importing the libraries that are required for this project. The Deep learning framework we are using is tensorflow. This is even to check if the correct version of tensorflow is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data Set\n",
    "\n",
    "MNIST Data Set is a collection of handwritten digits images comprising 60,000 training images and 10,000 test images. It usually used as a benchmark for the new computer vision and pattern recognition algorithms. The images here have been size-normalised and centered in fixed size image.\n",
    "\n",
    "Tensorflow has a module which helps us download this particular dataset, split it into training set, validation set, test set and creates one-hot vectors for labels of each image. The training set contains 55,000 images, validation set has 5,000 and test set has 10,000 images.\n",
    "\n",
    "**So why is it important to separate data into 3 sets?**\n",
    "\n",
    "These images here are 2D images each consisting an array of 28x28 values that have been flattened to get a rich structure of 784 dimensional vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Training Examples :  55000\n",
      "No. of Validation Examples :  5000\n",
      "No. of Test Examples :  10000\n",
      "Example of a one-hot encoded vector : \n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "Flattened Image Shape :  (784,)\n",
      "Example of a flattened image: \n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.38039219  0.37647063\n",
      "  0.3019608   0.46274513  0.2392157   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.35294119  0.5411765\n",
      "  0.92156869  0.92156869  0.92156869  0.92156869  0.92156869  0.92156869\n",
      "  0.98431379  0.98431379  0.97254908  0.99607849  0.96078438  0.92156869\n",
      "  0.74509805  0.08235294  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.54901963  0.98431379  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.74117649  0.09019608\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.88627458  0.99607849  0.81568635\n",
      "  0.78039223  0.78039223  0.78039223  0.78039223  0.54509807  0.2392157\n",
      "  0.2392157   0.2392157   0.2392157   0.2392157   0.50196081  0.8705883\n",
      "  0.99607849  0.99607849  0.74117649  0.08235294  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.14901961  0.32156864  0.0509804   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.13333334  0.83529419  0.99607849  0.99607849  0.45098042  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.32941177  0.99607849  0.99607849  0.91764712  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.32941177  0.99607849  0.99607849  0.91764712  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.41568631  0.6156863   0.99607849  0.99607849  0.95294124  0.20000002\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.09803922  0.45882356  0.89411771\n",
      "  0.89411771  0.89411771  0.99215692  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.94117653  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.26666668  0.4666667   0.86274517\n",
      "  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.99607849  0.99607849  0.99607849  0.55686277  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.14509805  0.73333335  0.99215692\n",
      "  0.99607849  0.99607849  0.99607849  0.87450987  0.80784321  0.80784321\n",
      "  0.29411766  0.26666668  0.84313732  0.99607849  0.99607849  0.45882356\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.44313729\n",
      "  0.8588236   0.99607849  0.94901967  0.89019614  0.45098042  0.34901962\n",
      "  0.12156864  0.          0.          0.          0.          0.7843138\n",
      "  0.99607849  0.9450981   0.16078432  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.66274512  0.99607849  0.6901961   0.24313727  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.18823531\n",
      "  0.90588242  0.99607849  0.91764712  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.07058824  0.48627454  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.32941177  0.99607849  0.99607849  0.65098041  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.54509807  0.99607849  0.9333334   0.22352943  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.82352948  0.98039222  0.99607849  0.65882355  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.94901967  0.99607849  0.93725497  0.22352943  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.34901962  0.98431379  0.9450981   0.33725491  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.01960784  0.80784321  0.96470594  0.6156863   0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.01568628  0.45882356  0.27058825  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of Training Examples : \",mnist.train.num_examples)\n",
    "print(\"No. of Validation Examples : \",mnist.validation.num_examples)\n",
    "print(\"No. of Test Examples : \",mnist.test.num_examples)\n",
    "print(\"Example of a one-hot encoded vector : \\n\",mnist.train.labels[0])\n",
    "print(\"Flattened Image Shape : \", mnist.train.images[0].shape)\n",
    "print(\"Example of a flattened image: \\n\", mnist.train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADlVJREFUeJzt3X+I5PV9x/Hnu9fEP1zZaNMee670EvAEEWo4sYWEekea\nYORAU4Lk/pBra7P5I5GWOFCxLO5RAlKmCYGWgq1HztKaFJqgBGmIcqsEQtAV64/IqZULXW+NiqZ1\n/zHVvvvHfl1m192duZnvzPe793k+YLjvr/nO677ny+93vt+Z+UZmIqk8v9Z0AEnNsPxSoSy/VCjL\nLxXK8kuFsvxSoSy/VCjLLxXK8kulysyJPYDsfczMzOTmaW15tDVbW3OZrT3ZBu3jSHv+iLg+Ik5H\nxEsRcce5Pv/2228f5eXHqq3Z2poLzDasprINXf6I2AP8HfA54ErgaERcWVcwSeM1yp7/WuClzHw5\nM38FfAe4sZ5YksYthv1WX0R8Abg+M/+0Gr8F+N3M/Oqm5eaAOYDp6emD8/Pz6/NmZ2dZXl4eMvp4\ntTVbW3OB2YZVZ7ZOp0NmxkALj3Dy7gvAP/aM3wL87bmc8Ot2u42fbNnu0dZsbc1ltvZkm8QJv1eA\ny3rGZ6tpknaBUcr/OHB5RHwsIj4MfBF4sJ5Yksbt14d9Yma+GxFfBX4I7AFOZOZztSWTNFZDlx8g\nMx8CHqopi6QJ8uO9UqEsv1Qoyy8VyvJLhbL8UqEsv1Qoyy8VyvJLhbL8UqEsv1Qoyy8VyvJLhbL8\nUqEsv1Qoyy8VyvJLhbL8UqEsv1Qoyy8VyvJLhbL8UqEsv1Qoyy8VyvJLhbL8UqEsv1Qoyy8VyvJL\nhbL8UqFGuktvRJwB3gbeA97NzGvqCCUBHDp0aMf5p06d2nH+4uLi+vDq6uqG5Q8fPjxKtPPCSOWv\nHM7MN2pYj6QJ8rBfKtSo5U/g4YhYioi5OgJJmozIzOGfHHFpZr4SEb8F/Ai4LTMf27TMHDAHMD09\nfXB+fn593uzsLMvLy0O//ji1NVtbc0H92S666KId5x84cGDH+aurq+vD7733Hnv27FkfP3369Gjh\nalTndut0OmRmDLLsSOXfsKKIBWA1M7s7LLPhxbrdLp1Op5bXr1tbs7U1F9Sfre4TflNTU+vjbTrh\nV/d2G7T8Qx/2R8SFEXHR+8PAZ4Fnh12fpMka5Wz/XuD7EfH+ev4lM/+9llSSxm7o8mfmy8Dv1JhF\nQ9rp8Lj30He3GTV773ZZXFzcML6wsLDjc/vNPx94qU8qlOWXCmX5pUJZfqlQll8qlOWXClXHt/o0\nonP5JNvi4iKbP5VZfdZCOifu+aVCWX6pUJZfKpTllwpl+aVCWX6pUJZfKpTX+VvgrrvuajpCcXbz\nV53r4p5fKpTllwpl+aVCWX6pUJZfKpTllwpl+aVCeZ1/Avp9X7/f/FKNc7t4nd89v1Qsyy8VyvJL\nhbL8UqEsv1Qoyy8VyvJLhep7nT8iTgBHgNcy86pq2iXAd4H9wBng5sx8a3wxd7fe390fxvHjx9eH\nDxw4sGH8fObnH8ZrkD3/t4HrN027A3gkMy8HHqnGJe0ifcufmY8Bb26afCNwsho+CdxUcy5JYzbs\ne/69mblSDb8K7K0pj6QJic33fdtyoYj9wA963vP/MjM/0jP/rcy8eJvnzgFzANPT0wfn5+fX583O\nzrK8vDxK/rGpM9vBgwdHev7Kysr68AUXXMA777yzYf7Zs2dHWn9d6v733Ldv347zZ2ZmBl7X6uoq\nU1NT6+NLS0tD56pbndut0+mQmQPdvHHY8p8GDmXmSkTMAIuZecUA69nwYt1ul06nM0jOiasz2yDb\neCebT/i98MILG+YvLCyMtP661P3v2e/vdS4/fLq4uLjhBGKbbm5a93YbtPzDHvY/CByrho8BDwy5\nHkkN6Vv+iLgf+AlwRUQsR8StwN3AZyLiReAPqnFJu0jf6/yZeXSbWZ+uOYu20fvd85mZmWK+iz7q\n/QwOHz68Pnz06NFiPh8xKD/hJxXK8kuFsvxSoSy/VCjLLxXK8kuF8qe7azDqV0/7XbrrnX/kyJHz\n5lLfuD+ZeL5ut7q455cKZfmlQll+qVCWXyqU5ZcKZfmlQll+qVBe56/BqF89ffTRR2tKsruMut28\nbj8a9/xSoSy/VCjLLxXK8kuFsvxSoSy/VCjLLxXK6/wD2uk7+95Kuhmlfj6iLu75pUJZfqlQll8q\nlOWXCmX5pUJZfqlQll8qVN/r/BFxAjgCvJaZV1XTFoAvAa9Xi92ZmQ+NK2QbeC1/OOP8bf5x/+7/\n+W6QPf+3geu3mP7NzLy6epzXxZfOR33Ln5mPAW9OIIukCRrlPf9tEfF0RJyIiItrSyRpIiIz+y8U\nsR/4Qc97/r3AG0ACfwXMZOafbPPcOWAOYHp6+uD8/Pz6vNnZWZaXl0f7G4zJ5mz79u3bdtmZmZmR\nXmtlZWXH+WfPnt02V5tslW2c221paWngZXfbdhtWp9MhM2OQZYcq/6Dztlh2w4t1u106nc4gOSdu\nc7adTi6N+kOUx48f33F+72vvpm0G491uEQP9Nw7svu02ikHLP9Rhf0T0/i/788Czw6xHUnMGudR3\nP3AI+GhELAN3AYci4mrWDvvPAF8eY0ZJY9C3/Jl5dIvJ944hS7Guu+66Hef3Hjrv27evtde3t8o2\nyqF9v7dDGo2f8JMKZfmlQll+qVCWXyqU5ZcKZfmlQvnT3S3Q7+vCvfMXFxc5enSrq6/Na3M2fZB7\nfqlQll8qlOWXCmX5pUJZfqlQll8qlOWXCuV1/gGN8jXaUX+xpkn9vlY7zr9bW7+6fL5wzy8VyvJL\nhbL8UqEsv1Qoyy8VyvJLhbL8UqG8zl+Dftej67xe3e12OXz4cG3rG5U/zb17ueeXCmX5pUJZfqlQ\nll8qlOWXCmX5pUJZfqlQfa/zR8RlwH3AXiCBezLzWxFxCfBdYD9wBrg5M98aX1Q14dSpU2Nbt9/X\nb9Yge/53gdsz80rg94CvRMSVwB3AI5l5OfBINS5pl+hb/sxcycwnq+G3geeBS4EbgZPVYieBm8YV\nUlL9zuk9f0TsBz4B/BTYm5kr1axXWXtbIGmXiMwcbMGIKeBR4OuZ+b2I+GVmfqRn/luZefEWz5sD\n5gCmp6cPzs/Pr8+bnZ1leXl5xL/CeLQ126RzXXHFFTvOn5qaWh9eXV3dMN7P0tLS0LnOVVv/PaHe\nbJ1Oh8yMgRbOzL4P4EPAD4Gv9Uw7DcxUwzPA6QHWk72Pbrebm6e15dHWbJPOderUqR0fvTaP93M+\nb7cmsw3S6czsf9gfEQHcCzyfmd/omfUgcKwaPgY80G9dktpjkK/0fhK4BXgmIp6qpt0J3A38a0Tc\nCvwcuHk8EdWkfrcP72dxcbGWHKpf3/Jn5o+B7d5DfLreOJImxU/4SYWy/FKhLL9UKMsvFcryS4Wy\n/FKh/Onuwo16Hb+fNv3MuDZyzy8VyvJLhbL8UqEsv1Qoyy8VyvJLhbL8UqG8zl+4Ua/z995m+8CB\nA952exdxzy8VyvJLhbL8UqEsv1Qoyy8VyvJLhbL8UqG8zq+R9P4u/8zMjL/Tv4u455cKZfmlQll+\nqVCWXyqU5ZcKZfmlQll+qVB9r/NHxGXAfcBeIIF7MvNbEbEAfAl4vVr0zsx8aFxBNR4LCwsjze91\n5MgRr/PvIoN8yOdd4PbMfDIiLgKWIuJH1bxvZmZ3fPEkjUvf8mfmCrBSDb8dEc8Dl447mKTxiswc\nfOGI/cBjwFXA14A/Bv4beIK1o4O3tnjOHDAHMD09fXB+fn593uzsLMvLy8OnH6O2ZmtrLjDbsOrM\n1ul0yMwYaOHMHOgBTAFLwB9W43uBPaydNPw6cGKAdWTvo9vt5uZpbXm0NVtbc5mtPdkG7fRAZ/sj\n4kPAvwH/nJnfY+0VfpGZ72Xm/wH/AFw7yLoktUPf8kdEAPcCz2fmN3qmz/Qs9nng2frjSRqXQc72\nfxK4BXgmIp6qpt0JHI2Iq1k71DgDfHksCSWNxSBn+38MbHUCwWv60i7mJ/ykQll+qVCWXyqU5ZcK\nZfmlQll+qVCWXyqU5ZcKZfmlQll+qVCWXyqU5ZcKZfmlQll+qVDn9Bt+I79YxOvAz3smfRR4Y2IB\nzk1bs7U1F5htWHVm++3M/M1BFpxo+T/w4hFPZOY1jQXYQVuztTUXmG1YTWXzsF8qlOWXCtV0+e9p\n+PV30tZsbc0FZhtWI9kafc8vqTlN7/klNaSR8kfE9RFxOiJeiog7msiwnYg4ExHPRMRTEfFEw1lO\nRMRrEfFsz7RLIuJHEfFi9efFLcq2EBGvVNvuqYi4oaFsl0XEqYj4WUQ8FxF/Vk1vdNvtkKuR7Tbx\nw/6I2AO8AHwGWAYeB45m5s8mGmQbEXEGuCYzG78mHBG/D6wC92XmVdW0vwbezMy7q/9xXpyZf9GS\nbAvAatN3bq5uKDPTe2dp4Cbgj2hw2+2Q62Ya2G5N7PmvBV7KzJcz81fAd4AbG8jRepn5GPDmpsk3\nAier4ZOs/cczcdtka4XMXMnMJ6vht4H37yzd6LbbIVcjmij/pcB/9Ywv065bfifwcEQsVXcYbpu9\n1W3TAV5l7YapbXJbRDxdvS1o5C1Jr+rO0p8AfkqLtt2mXNDAdvOE3wd9KjOvBj4HfKU6vG2lXHvP\n1qbLNX8PfBy4GlgB/qbJMBExxdoNZv88M/+nd16T226LXI1stybK/wpwWc/4bDWtFTLzlerP14Dv\n0767D//i/ZukVn++1nCedW26c/NWd5amBduuTXe8bqL8jwOXR8THIuLDwBeBBxvI8QERcWF1IoaI\nuBD4LO27+/CDwLFq+BjwQINZNmjLnZu3u7M0DW+71t3xOjMn/gBuYO2M/38Cf9lEhm1yfRz4j+rx\nXNPZgPtZOwz8X9bOjdwK/AbwCPAi8DBwSYuy/RPwDPA0a0WbaSjbp1g7pH8aeKp63ND0ttshVyPb\nzU/4SYXyhJ9UKMsvFcryS4Wy/FKhLL9UKMsvFcryS4Wy/FKh/h+xeyCUkjHsrAAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdf909012b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_array = mnist.train.images[np.random.randint(mnist.train.images.shape[0])]\n",
    "img_array = 255 * img_array\n",
    "img_array = img_array.astype(\"uint8\")\n",
    "#print(img_array.reshape([28,28]))\n",
    "plt.imshow(img_array.reshape([28,28]))\n",
    "plt.gray()\n",
    "plt.grid(True)\n",
    "plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build our network\n",
    "\n",
    "You'll have to build the necessary components given below alongwith us for designing the convolutional neural network.\n",
    "- `input_placeholders`\n",
    "- `init_weights_bias`\n",
    "- `conv2d`\n",
    "- `max_pool`\n",
    "- `flatten`\n",
    "- `fcn`\n",
    "- `output`\n",
    "- `cnn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Write Something about the 4 placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_placeholders():\n",
    "    \"\"\"\n",
    "    Create TF placeholders for inputs, targets, keep_prob, learning_rate\n",
    "    Return: A Tuple(inputs, targets, keep_prob, learning_rate)\n",
    "    \"\"\"\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None, 784], name=\"Inputs\")\n",
    "    targets = tf.placeholder(tf.float32, shape=[None, 10], name=\"Labels\")\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "    learning_rate = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "    \n",
    "    return inputs, targets, keep_prob, learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights_bias(w_shape, b_shape):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    weights = tf.Variable(tf.truncated_normal(w_shape, stddev=0.1), name=\"weights\")\n",
    "    bias = tf.Variable(tf.truncated_normal(b_shape), name=\"bias\")\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(inputs, weights, stride):\n",
    "    \"\"\"\n",
    "    Apply convolution operation to inputs tensor.\n",
    "    inputs: tensorflow tensor\n",
    "    weights: weights initialised for convolution operation\n",
    "    stride: 2d tuple for convolution\n",
    "    \"\"\"\n",
    "    return tf.nn.conv2d(inputs, weights, strides=[1,stride[0], stride[1], 1],name=\"conv\" ,padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool(inputs, kernel_size, stride):\n",
    "    \"\"\"\n",
    "    Apply max pooling operation to inputs tensor.\n",
    "    inputs: tensorflow tensor\n",
    "    kernel_size: 2d tuple for pooling\n",
    "    stride: 2d tuple for pooling\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(inputs, ksize=[1, kernel_size[0],kernel_size[1],1], \n",
    "                          strides=[1, stride[0], stride[1], 1], padding=\"SAME\", name=\"max_pool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(inputs):\n",
    "    \"\"\"\n",
    "    Flatten inputs tensor to (batch_size, flattened_image_size).\n",
    "    \"\"\"\n",
    "    shape_ip = inputs.get_shape().as_list()\n",
    "    return tf.reshape(inputs,[-1, shape_ip[1] * shape_ip[2] * shape_ip[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fcn(inputs, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to inputs tensor using weights and bias\n",
    "    inputs: tensorflow tensor\n",
    "    num_outputs: number of outputs the new tensor should be.\n",
    "    \"\"\"\n",
    "    weights = tf.Variable(tf.truncated_normal([inputs.get_shape().as_list()[1], num_outputs], stddev=0.1), name=\"weights\")\n",
    "    bias = tf.Variable(tf.truncated_normal([num_outputs]), name=\"bias\")\n",
    "    \n",
    "    fc = tf.add(tf.matmul(inputs, weights), bias)\n",
    "    fc = tf.nn.relu(fc)\n",
    "    \n",
    "    tf.summary.histogram(\"weights\", weights)\n",
    "    tf.summary.histogram(\"biases\", bias)\n",
    "    tf.summary.histogram(\"activations\", fc)\n",
    "    return fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outputs(inputs, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply an output layer to inputs tensor using weights and bias\n",
    "    inputs: tensorflow tensor\n",
    "    num_outputs: number of outputs the new tensor should be.\n",
    "    \"\"\"\n",
    "    weights = tf.Variable(tf.truncated_normal([inputs.get_shape().as_list()[1], num_outputs], stddev=0.1), name=\"weights\")\n",
    "    bias = tf.Variable(tf.truncated_normal([num_outputs]), name=\"weights\")\n",
    "    outputs = tf.add(tf.matmul(inputs, weights), bias, name=\"outputs\")\n",
    "    \n",
    "    tf.summary.histogram(\"weights\", weights)\n",
    "    tf.summary.histogram(\"biases\", bias)\n",
    "    tf.summary.histogram(\"activations\", outputs)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn(inputs, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional model using inputs tensor and use keep_prob while applying dropout \n",
    "    \"\"\"\n",
    "    inputs = tf.reshape(inputs, [-1, 28, 28, 1])\n",
    "    \n",
    "    tf.summary.image('input', inputs, 3)\n",
    "    \n",
    "    #Conv layer 1\n",
    "    with tf.name_scope(\"conv_1\"):\n",
    "        wc1, bc1 = init_weights_bias([5, 5, 1, 32], [32])\n",
    "        c1 = conv2d(inputs, wc1, [1,1])+bc1\n",
    "        r1 = tf.nn.relu(c1)\n",
    "        m1 = max_pool(r1, [2,2], [2,2])\n",
    "    \n",
    "    #Conv layer 2\n",
    "    with tf.name_scope(\"conv_2\"):\n",
    "        wc2, bc2 = init_weights_bias([5,5,32,64],[64])\n",
    "        c2 = conv2d(m1, wc2, [1,1])+bc2\n",
    "        r2 = tf.nn.relu(c2)\n",
    "        m2 = max_pool(r2, [2,2], [2,2])\n",
    "    \n",
    "    #Flatten the output of last conv layer\n",
    "    flat_m2 = flatten(m2)\n",
    "    \n",
    "    #Fully connected layer\n",
    "    with tf.name_scope(\"fc1\"):\n",
    "        fcn1 = fcn(flat_m2, 1024)\n",
    "    \n",
    "    #Dropout\n",
    "    drp1 = tf.nn.dropout(fcn1, keep_prob)\n",
    "    \n",
    "    #Output layer\n",
    "    with tf.name_scope(\"output_fc_layer\"):\n",
    "        out = outputs(drp1, 10)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_stats(sess, batch_train, batch_train_labels, batch_val, batch_val_labels, cost, accuracy, writer, step):\n",
    "    \"\"\"\n",
    "    Display intermediate results.\n",
    "    \"\"\"\n",
    "    train_data = sess.run([accuracy, summ, cost], feed_dict={\n",
    "        inputs: batch_train, targets: batch_train_labels, keep_prob: 1.0, learning_rate:0.0001})\n",
    "    val_data =sess.run([accuracy, cost], feed_dict={\n",
    "        inputs: batch_val, targets: batch_val_labels, keep_prob: 1.0, learning_rate:0.0001})\n",
    "    \n",
    "    writer.add_summary(train_data[1])\n",
    "    \n",
    "    print(\"Step {} Train_Loss : {:>10.4f} Train_Accuracy : {:.6f} Val_Loss : {:>10.4f} Val_Accuracy : {:.6f}\"\n",
    "         .format(step, train_data[2], train_data[0], val_data[0], val_data[1]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#Initialise Session\n",
    "sess = tf.Session()\n",
    "\n",
    "#Inputs\n",
    "inputs, targets, keep_prob, learning_rate = input_placeholders()\n",
    "\n",
    "#Model\n",
    "logits = cnn(inputs, keep_prob)\n",
    "\n",
    "#Loss Function\n",
    "with tf.name_scope(\"Loss_Function\"):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=logits))\n",
    "    tf.summary.scalar(\"loss\", cross_entropy)\n",
    "\n",
    "#Optimizer\n",
    "with tf.name_scope(\"Optimizer\"):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "# Report Accuracy\n",
    "with tf.name_scope(\"Accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(targets, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "\n",
    "#Define variable to save summaries\n",
    "summ = tf.summary.merge_all()\n",
    "\n",
    "#Initialise all variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#Create a saver object to save the model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#Write Graph to Tensorboard\n",
    "!rm -r log/\n",
    "writer = tf.summary.FileWriter(\"log/\")\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 Train_Loss :    18.0040 Train_Accuracy : 0.080000 Val_Loss :     0.0986 Val_Accuracy : 16.331438\n",
      "Step 100 Train_Loss :     1.3942 Train_Accuracy : 0.500000 Val_Loss :     0.6164 Val_Accuracy : 1.268946\n",
      "Step 200 Train_Loss :     0.8924 Train_Accuracy : 0.740000 Val_Loss :     0.8110 Val_Accuracy : 0.672059\n",
      "Step 300 Train_Loss :     0.2988 Train_Accuracy : 0.960000 Val_Loss :     0.8770 Val_Accuracy : 0.466590\n",
      "Step 400 Train_Loss :     0.4507 Train_Accuracy : 0.860000 Val_Loss :     0.8928 Val_Accuracy : 0.391549\n",
      "Step 500 Train_Loss :     0.4702 Train_Accuracy : 0.900000 Val_Loss :     0.9072 Val_Accuracy : 0.344046\n",
      "Step 600 Train_Loss :     0.4108 Train_Accuracy : 0.840000 Val_Loss :     0.9220 Val_Accuracy : 0.289190\n",
      "Step 700 Train_Loss :     0.1316 Train_Accuracy : 0.980000 Val_Loss :     0.9218 Val_Accuracy : 0.270509\n",
      "Step 800 Train_Loss :     0.1041 Train_Accuracy : 1.000000 Val_Loss :     0.9358 Val_Accuracy : 0.231991\n",
      "Step 900 Train_Loss :     0.1834 Train_Accuracy : 0.960000 Val_Loss :     0.9378 Val_Accuracy : 0.222914\n",
      "Step 1000 Train_Loss :     0.2540 Train_Accuracy : 0.920000 Val_Loss :     0.9428 Val_Accuracy : 0.197022\n",
      "Step 1100 Train_Loss :     0.3929 Train_Accuracy : 0.840000 Val_Loss :     0.9446 Val_Accuracy : 0.196493\n",
      "Step 1200 Train_Loss :     0.2520 Train_Accuracy : 0.920000 Val_Loss :     0.9494 Val_Accuracy : 0.180669\n",
      "Step 1300 Train_Loss :     0.1560 Train_Accuracy : 0.960000 Val_Loss :     0.9530 Val_Accuracy : 0.163445\n",
      "Step 1400 Train_Loss :     0.1866 Train_Accuracy : 0.920000 Val_Loss :     0.9542 Val_Accuracy : 0.160625\n",
      "Step 1500 Train_Loss :     0.2264 Train_Accuracy : 0.920000 Val_Loss :     0.9578 Val_Accuracy : 0.151138\n",
      "Step 1600 Train_Loss :     0.1061 Train_Accuracy : 0.960000 Val_Loss :     0.9592 Val_Accuracy : 0.137988\n",
      "Step 1700 Train_Loss :     0.0344 Train_Accuracy : 1.000000 Val_Loss :     0.9634 Val_Accuracy : 0.132332\n",
      "Step 1800 Train_Loss :     0.0435 Train_Accuracy : 1.000000 Val_Loss :     0.9628 Val_Accuracy : 0.127314\n",
      "Step 1900 Train_Loss :     0.2228 Train_Accuracy : 0.900000 Val_Loss :     0.9634 Val_Accuracy : 0.125571\n",
      "Step 2000 Train_Loss :     0.2497 Train_Accuracy : 0.920000 Val_Loss :     0.9686 Val_Accuracy : 0.116098\n",
      "Step 2100 Train_Loss :     0.0629 Train_Accuracy : 1.000000 Val_Loss :     0.9694 Val_Accuracy : 0.107498\n",
      "Step 2200 Train_Loss :     0.1494 Train_Accuracy : 0.940000 Val_Loss :     0.9698 Val_Accuracy : 0.108592\n",
      "Step 2300 Train_Loss :     0.0137 Train_Accuracy : 1.000000 Val_Loss :     0.9692 Val_Accuracy : 0.109522\n",
      "Step 2400 Train_Loss :     0.0615 Train_Accuracy : 1.000000 Val_Loss :     0.9714 Val_Accuracy : 0.100295\n",
      "Step 2500 Train_Loss :     0.1033 Train_Accuracy : 0.960000 Val_Loss :     0.9700 Val_Accuracy : 0.105276\n",
      "Step 2600 Train_Loss :     0.1011 Train_Accuracy : 0.980000 Val_Loss :     0.9688 Val_Accuracy : 0.106657\n",
      "Step 2700 Train_Loss :     0.0452 Train_Accuracy : 1.000000 Val_Loss :     0.9720 Val_Accuracy : 0.094321\n",
      "Step 2800 Train_Loss :     0.0460 Train_Accuracy : 1.000000 Val_Loss :     0.9760 Val_Accuracy : 0.088575\n",
      "Step 2900 Train_Loss :     0.1325 Train_Accuracy : 0.940000 Val_Loss :     0.9744 Val_Accuracy : 0.087677\n",
      "Step 3000 Train_Loss :     0.1770 Train_Accuracy : 0.960000 Val_Loss :     0.9720 Val_Accuracy : 0.087401\n",
      "Step 3100 Train_Loss :     0.0354 Train_Accuracy : 1.000000 Val_Loss :     0.9778 Val_Accuracy : 0.084681\n",
      "Step 3200 Train_Loss :     0.0715 Train_Accuracy : 0.980000 Val_Loss :     0.9756 Val_Accuracy : 0.090824\n",
      "Step 3300 Train_Loss :     0.1324 Train_Accuracy : 0.980000 Val_Loss :     0.9778 Val_Accuracy : 0.080451\n",
      "Step 3400 Train_Loss :     0.0462 Train_Accuracy : 0.980000 Val_Loss :     0.9752 Val_Accuracy : 0.081699\n",
      "Step 3500 Train_Loss :     0.0725 Train_Accuracy : 0.980000 Val_Loss :     0.9782 Val_Accuracy : 0.076514\n",
      "Step 3600 Train_Loss :     0.0189 Train_Accuracy : 1.000000 Val_Loss :     0.9780 Val_Accuracy : 0.077324\n",
      "Step 3700 Train_Loss :     0.0434 Train_Accuracy : 0.980000 Val_Loss :     0.9782 Val_Accuracy : 0.075863\n",
      "Step 3800 Train_Loss :     0.0180 Train_Accuracy : 1.000000 Val_Loss :     0.9786 Val_Accuracy : 0.072037\n",
      "Step 3900 Train_Loss :     0.1195 Train_Accuracy : 0.940000 Val_Loss :     0.9798 Val_Accuracy : 0.072408\n",
      "Step 4000 Train_Loss :     0.0087 Train_Accuracy : 1.000000 Val_Loss :     0.9786 Val_Accuracy : 0.072705\n",
      "Step 4100 Train_Loss :     0.0570 Train_Accuracy : 0.980000 Val_Loss :     0.9806 Val_Accuracy : 0.064491\n",
      "Step 4200 Train_Loss :     0.0114 Train_Accuracy : 1.000000 Val_Loss :     0.9820 Val_Accuracy : 0.065699\n",
      "Step 4300 Train_Loss :     0.0822 Train_Accuracy : 0.980000 Val_Loss :     0.9812 Val_Accuracy : 0.062599\n",
      "Step 4400 Train_Loss :     0.0404 Train_Accuracy : 0.980000 Val_Loss :     0.9832 Val_Accuracy : 0.061123\n",
      "Step 4500 Train_Loss :     0.2025 Train_Accuracy : 0.980000 Val_Loss :     0.9796 Val_Accuracy : 0.074735\n",
      "Step 4600 Train_Loss :     0.0476 Train_Accuracy : 0.980000 Val_Loss :     0.9812 Val_Accuracy : 0.062600\n",
      "Step 4700 Train_Loss :     0.0287 Train_Accuracy : 1.000000 Val_Loss :     0.9824 Val_Accuracy : 0.060030\n",
      "Step 4800 Train_Loss :     0.0213 Train_Accuracy : 1.000000 Val_Loss :     0.9826 Val_Accuracy : 0.060839\n",
      "Step 4900 Train_Loss :     0.0349 Train_Accuracy : 0.980000 Val_Loss :     0.9830 Val_Accuracy : 0.059354\n",
      "Step 5000 Train_Loss :     0.0170 Train_Accuracy : 1.000000 Val_Loss :     0.9788 Val_Accuracy : 0.063433\n",
      "Step 5100 Train_Loss :     0.0103 Train_Accuracy : 1.000000 Val_Loss :     0.9840 Val_Accuracy : 0.054610\n",
      "Step 5200 Train_Loss :     0.0178 Train_Accuracy : 1.000000 Val_Loss :     0.9812 Val_Accuracy : 0.060970\n",
      "Step 5300 Train_Loss :     0.0029 Train_Accuracy : 1.000000 Val_Loss :     0.9826 Val_Accuracy : 0.061545\n",
      "Step 5400 Train_Loss :     0.0396 Train_Accuracy : 0.980000 Val_Loss :     0.9832 Val_Accuracy : 0.061690\n",
      "Step 5500 Train_Loss :     0.1128 Train_Accuracy : 0.960000 Val_Loss :     0.9832 Val_Accuracy : 0.058558\n",
      "Step 5600 Train_Loss :     0.0155 Train_Accuracy : 1.000000 Val_Loss :     0.9850 Val_Accuracy : 0.052261\n",
      "Step 5700 Train_Loss :     0.1200 Train_Accuracy : 0.980000 Val_Loss :     0.9844 Val_Accuracy : 0.055920\n",
      "Step 5800 Train_Loss :     0.0319 Train_Accuracy : 1.000000 Val_Loss :     0.9820 Val_Accuracy : 0.061906\n",
      "Step 5900 Train_Loss :     0.0093 Train_Accuracy : 1.000000 Val_Loss :     0.9840 Val_Accuracy : 0.057168\n",
      "Step 6000 Train_Loss :     0.0040 Train_Accuracy : 1.000000 Val_Loss :     0.9854 Val_Accuracy : 0.052409\n",
      "Step 6100 Train_Loss :     0.0345 Train_Accuracy : 0.980000 Val_Loss :     0.9848 Val_Accuracy : 0.053774\n",
      "Step 6200 Train_Loss :     0.0597 Train_Accuracy : 0.960000 Val_Loss :     0.9850 Val_Accuracy : 0.051358\n",
      "Step 6300 Train_Loss :     0.0173 Train_Accuracy : 1.000000 Val_Loss :     0.9860 Val_Accuracy : 0.049341\n",
      "Step 6400 Train_Loss :     0.0054 Train_Accuracy : 1.000000 Val_Loss :     0.9844 Val_Accuracy : 0.059999\n",
      "Step 6500 Train_Loss :     0.0043 Train_Accuracy : 1.000000 Val_Loss :     0.9856 Val_Accuracy : 0.052012\n",
      "Step 6600 Train_Loss :     0.0072 Train_Accuracy : 1.000000 Val_Loss :     0.9850 Val_Accuracy : 0.050640\n",
      "Step 6700 Train_Loss :     0.0080 Train_Accuracy : 1.000000 Val_Loss :     0.9864 Val_Accuracy : 0.047730\n",
      "Step 6800 Train_Loss :     0.1152 Train_Accuracy : 0.980000 Val_Loss :     0.9870 Val_Accuracy : 0.047049\n",
      "Step 6900 Train_Loss :     0.0760 Train_Accuracy : 0.980000 Val_Loss :     0.9844 Val_Accuracy : 0.056238\n",
      "Step 7000 Train_Loss :     0.0031 Train_Accuracy : 1.000000 Val_Loss :     0.9856 Val_Accuracy : 0.046399\n",
      "Step 7100 Train_Loss :     0.1087 Train_Accuracy : 0.960000 Val_Loss :     0.9864 Val_Accuracy : 0.046637\n",
      "Step 7200 Train_Loss :     0.0376 Train_Accuracy : 0.980000 Val_Loss :     0.9862 Val_Accuracy : 0.045977\n",
      "Step 7300 Train_Loss :     0.0404 Train_Accuracy : 0.980000 Val_Loss :     0.9874 Val_Accuracy : 0.046434\n",
      "Step 7400 Train_Loss :     0.0084 Train_Accuracy : 1.000000 Val_Loss :     0.9864 Val_Accuracy : 0.045268\n",
      "Step 7500 Train_Loss :     0.1250 Train_Accuracy : 0.980000 Val_Loss :     0.9866 Val_Accuracy : 0.045902\n",
      "Step 7600 Train_Loss :     0.0100 Train_Accuracy : 1.000000 Val_Loss :     0.9862 Val_Accuracy : 0.045391\n",
      "Step 7700 Train_Loss :     0.0182 Train_Accuracy : 1.000000 Val_Loss :     0.9880 Val_Accuracy : 0.045075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7800 Train_Loss :     0.0610 Train_Accuracy : 0.980000 Val_Loss :     0.9870 Val_Accuracy : 0.043238\n",
      "Step 7900 Train_Loss :     0.0018 Train_Accuracy : 1.000000 Val_Loss :     0.9876 Val_Accuracy : 0.041158\n",
      "Step 8000 Train_Loss :     0.0229 Train_Accuracy : 1.000000 Val_Loss :     0.9876 Val_Accuracy : 0.044080\n",
      "Step 8100 Train_Loss :     0.0016 Train_Accuracy : 1.000000 Val_Loss :     0.9874 Val_Accuracy : 0.044476\n",
      "Step 8200 Train_Loss :     0.0339 Train_Accuracy : 0.980000 Val_Loss :     0.9882 Val_Accuracy : 0.042768\n",
      "Step 8300 Train_Loss :     0.0154 Train_Accuracy : 1.000000 Val_Loss :     0.9876 Val_Accuracy : 0.045025\n",
      "Step 8400 Train_Loss :     0.0041 Train_Accuracy : 1.000000 Val_Loss :     0.9898 Val_Accuracy : 0.038930\n",
      "Step 8500 Train_Loss :     0.0373 Train_Accuracy : 0.980000 Val_Loss :     0.9884 Val_Accuracy : 0.042329\n",
      "Step 8600 Train_Loss :     0.0055 Train_Accuracy : 1.000000 Val_Loss :     0.9878 Val_Accuracy : 0.042309\n",
      "Step 8700 Train_Loss :     0.0396 Train_Accuracy : 0.980000 Val_Loss :     0.9874 Val_Accuracy : 0.044206\n",
      "Step 8800 Train_Loss :     0.0055 Train_Accuracy : 1.000000 Val_Loss :     0.9872 Val_Accuracy : 0.041124\n",
      "Step 8900 Train_Loss :     0.0080 Train_Accuracy : 1.000000 Val_Loss :     0.9870 Val_Accuracy : 0.042564\n",
      "Step 9000 Train_Loss :     0.0056 Train_Accuracy : 1.000000 Val_Loss :     0.9882 Val_Accuracy : 0.042679\n",
      "Step 9100 Train_Loss :     0.0603 Train_Accuracy : 0.980000 Val_Loss :     0.9890 Val_Accuracy : 0.041037\n",
      "Step 9200 Train_Loss :     0.0800 Train_Accuracy : 0.980000 Val_Loss :     0.9884 Val_Accuracy : 0.040278\n",
      "Step 9300 Train_Loss :     0.0349 Train_Accuracy : 1.000000 Val_Loss :     0.9882 Val_Accuracy : 0.041113\n",
      "Step 9400 Train_Loss :     0.0499 Train_Accuracy : 0.980000 Val_Loss :     0.9878 Val_Accuracy : 0.042300\n",
      "Step 9500 Train_Loss :     0.0074 Train_Accuracy : 1.000000 Val_Loss :     0.9878 Val_Accuracy : 0.039863\n",
      "Step 9600 Train_Loss :     0.0229 Train_Accuracy : 1.000000 Val_Loss :     0.9884 Val_Accuracy : 0.036135\n",
      "Step 9700 Train_Loss :     0.0281 Train_Accuracy : 0.980000 Val_Loss :     0.9898 Val_Accuracy : 0.037312\n",
      "Step 9800 Train_Loss :     0.0362 Train_Accuracy : 0.980000 Val_Loss :     0.9892 Val_Accuracy : 0.042561\n",
      "Step 9900 Train_Loss :     0.0129 Train_Accuracy : 1.000000 Val_Loss :     0.9904 Val_Accuracy : 0.036060\n",
      "Step 10000 Train_Loss :     0.0399 Train_Accuracy : 0.980000 Val_Loss :     0.9894 Val_Accuracy : 0.039917\n",
      "Step 10100 Train_Loss :     0.0139 Train_Accuracy : 1.000000 Val_Loss :     0.9894 Val_Accuracy : 0.036556\n",
      "Step 10200 Train_Loss :     0.0087 Train_Accuracy : 1.000000 Val_Loss :     0.9882 Val_Accuracy : 0.039305\n",
      "Step 10300 Train_Loss :     0.0017 Train_Accuracy : 1.000000 Val_Loss :     0.9892 Val_Accuracy : 0.037867\n",
      "Step 10400 Train_Loss :     0.0090 Train_Accuracy : 1.000000 Val_Loss :     0.9894 Val_Accuracy : 0.038205\n",
      "Step 10500 Train_Loss :     0.0041 Train_Accuracy : 1.000000 Val_Loss :     0.9886 Val_Accuracy : 0.038533\n",
      "Step 10600 Train_Loss :     0.0018 Train_Accuracy : 1.000000 Val_Loss :     0.9898 Val_Accuracy : 0.035424\n",
      "Step 10700 Train_Loss :     0.0007 Train_Accuracy : 1.000000 Val_Loss :     0.9884 Val_Accuracy : 0.041777\n",
      "Step 10800 Train_Loss :     0.0035 Train_Accuracy : 1.000000 Val_Loss :     0.9886 Val_Accuracy : 0.035611\n",
      "Step 10900 Train_Loss :     0.0076 Train_Accuracy : 1.000000 Val_Loss :     0.9892 Val_Accuracy : 0.034914\n",
      "Step 11000 Train_Loss :     0.0440 Train_Accuracy : 0.980000 Val_Loss :     0.9886 Val_Accuracy : 0.040337\n",
      "Step 11100 Train_Loss :     0.0049 Train_Accuracy : 1.000000 Val_Loss :     0.9898 Val_Accuracy : 0.038894\n",
      "Step 11200 Train_Loss :     0.0257 Train_Accuracy : 1.000000 Val_Loss :     0.9890 Val_Accuracy : 0.037598\n",
      "Step 11300 Train_Loss :     0.0106 Train_Accuracy : 1.000000 Val_Loss :     0.9886 Val_Accuracy : 0.040056\n",
      "Step 11400 Train_Loss :     0.0085 Train_Accuracy : 1.000000 Val_Loss :     0.9898 Val_Accuracy : 0.037853\n",
      "Step 11500 Train_Loss :     0.0688 Train_Accuracy : 0.960000 Val_Loss :     0.9898 Val_Accuracy : 0.037745\n",
      "Step 11600 Train_Loss :     0.0160 Train_Accuracy : 1.000000 Val_Loss :     0.9904 Val_Accuracy : 0.036556\n",
      "Step 11700 Train_Loss :     0.0450 Train_Accuracy : 0.980000 Val_Loss :     0.9892 Val_Accuracy : 0.036374\n",
      "Step 11800 Train_Loss :     0.0181 Train_Accuracy : 1.000000 Val_Loss :     0.9894 Val_Accuracy : 0.038363\n",
      "Step 11900 Train_Loss :     0.0099 Train_Accuracy : 1.000000 Val_Loss :     0.9892 Val_Accuracy : 0.038002\n",
      "Step 12000 Train_Loss :     0.0142 Train_Accuracy : 1.000000 Val_Loss :     0.9894 Val_Accuracy : 0.038163\n",
      "Step 12100 Train_Loss :     0.0123 Train_Accuracy : 1.000000 Val_Loss :     0.9886 Val_Accuracy : 0.037891\n",
      "Step 12200 Train_Loss :     0.1107 Train_Accuracy : 0.980000 Val_Loss :     0.9894 Val_Accuracy : 0.036604\n",
      "Step 12300 Train_Loss :     0.0036 Train_Accuracy : 1.000000 Val_Loss :     0.9886 Val_Accuracy : 0.037255\n",
      "Step 12400 Train_Loss :     0.0401 Train_Accuracy : 0.980000 Val_Loss :     0.9894 Val_Accuracy : 0.037350\n",
      "Step 12500 Train_Loss :     0.0004 Train_Accuracy : 1.000000 Val_Loss :     0.9914 Val_Accuracy : 0.035549\n",
      "Step 12600 Train_Loss :     0.0017 Train_Accuracy : 1.000000 Val_Loss :     0.9904 Val_Accuracy : 0.034898\n",
      "Step 12700 Train_Loss :     0.0007 Train_Accuracy : 1.000000 Val_Loss :     0.9910 Val_Accuracy : 0.034894\n",
      "Step 12800 Train_Loss :     0.0255 Train_Accuracy : 0.980000 Val_Loss :     0.9892 Val_Accuracy : 0.038537\n",
      "Step 12900 Train_Loss :     0.0117 Train_Accuracy : 1.000000 Val_Loss :     0.9904 Val_Accuracy : 0.034942\n",
      "Step 13000 Train_Loss :     0.0092 Train_Accuracy : 1.000000 Val_Loss :     0.9888 Val_Accuracy : 0.040802\n",
      "Step 13100 Train_Loss :     0.0180 Train_Accuracy : 1.000000 Val_Loss :     0.9906 Val_Accuracy : 0.035375\n",
      "Step 13200 Train_Loss :     0.0018 Train_Accuracy : 1.000000 Val_Loss :     0.9898 Val_Accuracy : 0.038106\n",
      "Step 13300 Train_Loss :     0.0027 Train_Accuracy : 1.000000 Val_Loss :     0.9902 Val_Accuracy : 0.037417\n",
      "Step 13400 Train_Loss :     0.0049 Train_Accuracy : 1.000000 Val_Loss :     0.9874 Val_Accuracy : 0.041441\n",
      "Step 13500 Train_Loss :     0.0210 Train_Accuracy : 0.980000 Val_Loss :     0.9878 Val_Accuracy : 0.038040\n",
      "Step 13600 Train_Loss :     0.0024 Train_Accuracy : 1.000000 Val_Loss :     0.9906 Val_Accuracy : 0.035426\n",
      "Step 13700 Train_Loss :     0.0013 Train_Accuracy : 1.000000 Val_Loss :     0.9904 Val_Accuracy : 0.034665\n",
      "Step 13800 Train_Loss :     0.0049 Train_Accuracy : 1.000000 Val_Loss :     0.9906 Val_Accuracy : 0.036040\n",
      "Step 13900 Train_Loss :     0.0205 Train_Accuracy : 0.980000 Val_Loss :     0.9910 Val_Accuracy : 0.036685\n",
      "Step 14000 Train_Loss :     0.0269 Train_Accuracy : 1.000000 Val_Loss :     0.9902 Val_Accuracy : 0.033345\n",
      "Step 14100 Train_Loss :     0.0294 Train_Accuracy : 0.980000 Val_Loss :     0.9900 Val_Accuracy : 0.036893\n",
      "Step 14200 Train_Loss :     0.0062 Train_Accuracy : 1.000000 Val_Loss :     0.9918 Val_Accuracy : 0.030976\n",
      "Step 14300 Train_Loss :     0.0023 Train_Accuracy : 1.000000 Val_Loss :     0.9906 Val_Accuracy : 0.036908\n",
      "Step 14400 Train_Loss :     0.0011 Train_Accuracy : 1.000000 Val_Loss :     0.9912 Val_Accuracy : 0.032546\n",
      "Step 14500 Train_Loss :     0.0033 Train_Accuracy : 1.000000 Val_Loss :     0.9906 Val_Accuracy : 0.032558\n",
      "Step 14600 Train_Loss :     0.0006 Train_Accuracy : 1.000000 Val_Loss :     0.9910 Val_Accuracy : 0.033750\n",
      "Step 14700 Train_Loss :     0.0001 Train_Accuracy : 1.000000 Val_Loss :     0.9910 Val_Accuracy : 0.033230\n",
      "Step 14800 Train_Loss :     0.0717 Train_Accuracy : 0.980000 Val_Loss :     0.9914 Val_Accuracy : 0.032922\n",
      "Step 14900 Train_Loss :     0.0121 Train_Accuracy : 1.000000 Val_Loss :     0.9904 Val_Accuracy : 0.037019\n",
      "Step 15000 Train_Loss :     0.0016 Train_Accuracy : 1.000000 Val_Loss :     0.9892 Val_Accuracy : 0.035592\n",
      "Step 15100 Train_Loss :     0.0309 Train_Accuracy : 0.980000 Val_Loss :     0.9898 Val_Accuracy : 0.034584\n",
      "Step 15200 Train_Loss :     0.0027 Train_Accuracy : 1.000000 Val_Loss :     0.9908 Val_Accuracy : 0.033640\n",
      "Step 15300 Train_Loss :     0.0069 Train_Accuracy : 1.000000 Val_Loss :     0.9908 Val_Accuracy : 0.030776\n",
      "Step 15400 Train_Loss :     0.0128 Train_Accuracy : 1.000000 Val_Loss :     0.9910 Val_Accuracy : 0.032419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15500 Train_Loss :     0.0143 Train_Accuracy : 1.000000 Val_Loss :     0.9920 Val_Accuracy : 0.032144\n",
      "Step 15600 Train_Loss :     0.0012 Train_Accuracy : 1.000000 Val_Loss :     0.9916 Val_Accuracy : 0.036387\n",
      "Step 15700 Train_Loss :     0.0004 Train_Accuracy : 1.000000 Val_Loss :     0.9916 Val_Accuracy : 0.033052\n",
      "Step 15800 Train_Loss :     0.0038 Train_Accuracy : 1.000000 Val_Loss :     0.9920 Val_Accuracy : 0.032052\n",
      "Step 15900 Train_Loss :     0.0028 Train_Accuracy : 1.000000 Val_Loss :     0.9918 Val_Accuracy : 0.034141\n",
      "Step 16000 Train_Loss :     0.0321 Train_Accuracy : 0.980000 Val_Loss :     0.9908 Val_Accuracy : 0.032138\n",
      "Step 16100 Train_Loss :     0.0044 Train_Accuracy : 1.000000 Val_Loss :     0.9916 Val_Accuracy : 0.036724\n",
      "Step 16200 Train_Loss :     0.0013 Train_Accuracy : 1.000000 Val_Loss :     0.9922 Val_Accuracy : 0.032660\n",
      "Step 16300 Train_Loss :     0.0013 Train_Accuracy : 1.000000 Val_Loss :     0.9910 Val_Accuracy : 0.033202\n",
      "Step 16400 Train_Loss :     0.0251 Train_Accuracy : 1.000000 Val_Loss :     0.9908 Val_Accuracy : 0.032137\n",
      "Step 16500 Train_Loss :     0.0136 Train_Accuracy : 1.000000 Val_Loss :     0.9918 Val_Accuracy : 0.034976\n",
      "Step 16600 Train_Loss :     0.0016 Train_Accuracy : 1.000000 Val_Loss :     0.9922 Val_Accuracy : 0.031756\n",
      "Step 16700 Train_Loss :     0.0191 Train_Accuracy : 1.000000 Val_Loss :     0.9916 Val_Accuracy : 0.035944\n",
      "Step 16800 Train_Loss :     0.0018 Train_Accuracy : 1.000000 Val_Loss :     0.9916 Val_Accuracy : 0.034888\n",
      "Step 16900 Train_Loss :     0.0014 Train_Accuracy : 1.000000 Val_Loss :     0.9920 Val_Accuracy : 0.031565\n",
      "Step 17000 Train_Loss :     0.0013 Train_Accuracy : 1.000000 Val_Loss :     0.9914 Val_Accuracy : 0.031881\n",
      "Step 17100 Train_Loss :     0.0092 Train_Accuracy : 1.000000 Val_Loss :     0.9902 Val_Accuracy : 0.035450\n",
      "Step 17200 Train_Loss :     0.0001 Train_Accuracy : 1.000000 Val_Loss :     0.9918 Val_Accuracy : 0.032031\n",
      "Step 17300 Train_Loss :     0.0049 Train_Accuracy : 1.000000 Val_Loss :     0.9922 Val_Accuracy : 0.031492\n",
      "Step 17400 Train_Loss :     0.0013 Train_Accuracy : 1.000000 Val_Loss :     0.9912 Val_Accuracy : 0.031890\n",
      "Step 17500 Train_Loss :     0.0507 Train_Accuracy : 0.960000 Val_Loss :     0.9902 Val_Accuracy : 0.032445\n",
      "Step 17600 Train_Loss :     0.0039 Train_Accuracy : 1.000000 Val_Loss :     0.9924 Val_Accuracy : 0.033076\n",
      "Step 17700 Train_Loss :     0.0011 Train_Accuracy : 1.000000 Val_Loss :     0.9928 Val_Accuracy : 0.031508\n",
      "Step 17800 Train_Loss :     0.0006 Train_Accuracy : 1.000000 Val_Loss :     0.9916 Val_Accuracy : 0.031189\n",
      "Step 17900 Train_Loss :     0.0003 Train_Accuracy : 1.000000 Val_Loss :     0.9914 Val_Accuracy : 0.033745\n",
      "Step 18000 Train_Loss :     0.0023 Train_Accuracy : 1.000000 Val_Loss :     0.9916 Val_Accuracy : 0.030529\n",
      "Step 18100 Train_Loss :     0.0195 Train_Accuracy : 0.980000 Val_Loss :     0.9906 Val_Accuracy : 0.033637\n",
      "Step 18200 Train_Loss :     0.0070 Train_Accuracy : 1.000000 Val_Loss :     0.9918 Val_Accuracy : 0.032624\n",
      "Step 18300 Train_Loss :     0.0001 Train_Accuracy : 1.000000 Val_Loss :     0.9908 Val_Accuracy : 0.034283\n",
      "Step 18400 Train_Loss :     0.0018 Train_Accuracy : 1.000000 Val_Loss :     0.9922 Val_Accuracy : 0.030015\n",
      "Step 18500 Train_Loss :     0.0053 Train_Accuracy : 1.000000 Val_Loss :     0.9924 Val_Accuracy : 0.030831\n",
      "Step 18600 Train_Loss :     0.0434 Train_Accuracy : 0.980000 Val_Loss :     0.9912 Val_Accuracy : 0.031304\n",
      "Step 18700 Train_Loss :     0.0013 Train_Accuracy : 1.000000 Val_Loss :     0.9902 Val_Accuracy : 0.039352\n",
      "Step 18800 Train_Loss :     0.0042 Train_Accuracy : 1.000000 Val_Loss :     0.9926 Val_Accuracy : 0.028511\n",
      "Step 18900 Train_Loss :     0.0007 Train_Accuracy : 1.000000 Val_Loss :     0.9922 Val_Accuracy : 0.031408\n",
      "Step 19000 Train_Loss :     0.0020 Train_Accuracy : 1.000000 Val_Loss :     0.9922 Val_Accuracy : 0.033722\n",
      "Step 19100 Train_Loss :     0.0234 Train_Accuracy : 0.980000 Val_Loss :     0.9906 Val_Accuracy : 0.033189\n",
      "Step 19200 Train_Loss :     0.0001 Train_Accuracy : 1.000000 Val_Loss :     0.9916 Val_Accuracy : 0.032438\n",
      "Step 19300 Train_Loss :     0.0043 Train_Accuracy : 1.000000 Val_Loss :     0.9922 Val_Accuracy : 0.032447\n",
      "Step 19400 Train_Loss :     0.0415 Train_Accuracy : 0.980000 Val_Loss :     0.9912 Val_Accuracy : 0.033992\n",
      "Step 19500 Train_Loss :     0.3695 Train_Accuracy : 0.980000 Val_Loss :     0.9908 Val_Accuracy : 0.035715\n",
      "Step 19600 Train_Loss :     0.0007 Train_Accuracy : 1.000000 Val_Loss :     0.9920 Val_Accuracy : 0.034256\n",
      "Step 19700 Train_Loss :     0.0001 Train_Accuracy : 1.000000 Val_Loss :     0.9918 Val_Accuracy : 0.031994\n",
      "Step 19800 Train_Loss :     0.0265 Train_Accuracy : 0.980000 Val_Loss :     0.9920 Val_Accuracy : 0.034271\n",
      "Step 19900 Train_Loss :     0.0003 Train_Accuracy : 1.000000 Val_Loss :     0.9922 Val_Accuracy : 0.033382\n",
      "\n",
      "Test accuracy : 0.9914001226425171\n"
     ]
    }
   ],
   "source": [
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i % 100 == 0:\n",
    "        display_stats(sess, batch[0], batch[1], mnist.validation.images, mnist.validation.labels, \n",
    "                      cross_entropy, accuracy, writer, i)\n",
    "        saver.save(sess, 'trained/test_model')\n",
    "    sess.run(train_step,feed_dict={inputs: batch[0], targets: batch[1], keep_prob: 0.5, learning_rate:0.0001})\n",
    "\n",
    "print('\\nTest accuracy : {}'.format(sess.run(accuracy,feed_dict={\n",
    "    inputs: mnist.test.images, targets: mnist.test.labels, keep_prob: 1.0, learning_rate:0.0001})))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using the Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trained/test_model\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0b013b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "saver=tf.train.import_meta_graph('trained/test_model.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./trained/'))\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "output = graph.get_tensor_by_name(\"output_fc_layer/outputs:0\")\n",
    "\n",
    "inputs = graph.get_tensor_by_name(\"Inputs:0\")\n",
    "targets = graph.get_tensor_by_name(\"Labels:0\")\n",
    "keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "learning_rate = graph.get_tensor_by_name(\"learning_rate:0\")\n",
    "\n",
    "pred = tf.nn.softmax(output)\n",
    "img_predict_index = np.random.randint(mnist.test.images.shape[0])\n",
    "img_array = 255 * mnist.test.images[img_predict_index]\n",
    "img_array = img_array.astype(\"uint8\")\n",
    "plt.imshow(img_array.reshape([28,28]))\n",
    "plt.gray()\n",
    "\n",
    "predictions = sess.run(pred, feed_dict={inputs:mnist.test.images[img_predict_index].reshape(1,784), \n",
    "                                        targets: mnist.test.labels[img_predict_index].reshape(1,10), \n",
    "                                        keep_prob:1.0, learning_rate:0.0001})\n",
    "\n",
    "print(np.argmax(predictions[0]))\n",
    "\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
